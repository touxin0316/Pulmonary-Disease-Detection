# -*- coding: utf-8 -*-
"""107000109_HW4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ser2aQSvmtlyP6xRL3czKNisZ4CtpIBc
"""

import numpy as np
import pandas as pd
from PIL import Image

from google.colab import drive
drive.mount('/content/drive')

!unzip # FILE PATH

X_train = []
for i in range(10000):
    X_train.append(np.asarray(Image.open("drive/MyDrive/HW4_data/public/train_{i}.jpg".format(i=i))))
    
df_train = pd.read_csv("drive/MyDrive/HW4_data/public/train_label.csv", index_col=0)

X_val = []
for i in range(1000):
    X_val.append(np.asarray(Image.open("drive/MyDrive/HW4_data/public/val_{i}.jpg".format(i=i))))
    
df_val = pd.read_csv("drive/MyDrive/HW4_data/public/val_label.csv", index_col=0)

X_test = []
for i in range(1500):
    X_test.append(np.asarray(Image.open("drive/MyDrive/HW4_data/private/test_{i}.jpg".format(i=i))))

df_test_demo = pd.read_csv("drive/MyDrive/HW4_data/private/test_demo.csv", index_col=0)

print(X_val[0])

X_train_array = np.asarray(X_train)
X_val_array = np.asarray(X_val)
X_test_array = np.asarray(X_test)
print(X_train_array.shape)
print(X_val_array.shape)
print(X_test_array.shape)

X_train_1 = np.array(X_train_array).reshape(X_train_array.shape[0],128,128,1).astype("float32") / 255
X_val_1 = np.array(X_val_array).reshape(X_val_array.shape[0],128,128,1).astype("float32") / 255
X_test_1 = np.array(X_test_array).reshape(X_test_array.shape[0],128,128,1).astype("float32") / 255
#print(X_val_1)

from matplotlib import pyplot as plt
plt.imshow(X_train_array[0], cmap='gray')
print(X_train[0].shape)

Y_train = df_train['Edema']
Y_val = df_val['Edema']
#Y_test = df_test_demo['Edema']
print(Y_train[0])

import tensorflow.keras.utils as np_utils
Y_train_onehot = np_utils.to_categorical(Y_train)
Y_val_onehot = np_utils.to_categorical(Y_val)
print(Y_val_onehot)

# multiclass 對AGE項做one-hot
#0 = 00000
#1 = 01000
#2 = 00100
#3 = 00010
#4 = 00001

Age = pd.DataFrame(columns = ['age_0','age_1','age_2','age_3','age_4'])
Age_val = pd.DataFrame(columns = ['age_0','age_1','age_2','age_3','age_4'])
for i in range(len(df_train)) :
  if df_train['Age'].iloc[0] == 0 :
    row = pd.Series([1,0,0,0,0],index=['age_0','age_1','age_2','age_3','age_4'])
    Age = Age.append(row,ignore_index=True)
  elif df_train['Age'].iloc[i] == 1 :
    row = pd.Series([0,1,0,0,0],index=['age_0','age_1','age_2','age_3','age_4'])
    Age = Age.append(row,ignore_index=True)
  elif df_train['Age'].iloc[i] == 2 :
    row = pd.Series([0,0,1,0,0],index=['age_0','age_1','age_2','age_3','age_4'])
    Age = Age.append(row,ignore_index=True)
  elif df_train['Age'].iloc[i] == 3 :
    row = pd.Series([0,0,0,1,0],index=['age_0','age_1','age_2','age_3','age_4'])
    Age = Age.append(row,ignore_index=True)
  elif df_train['Age'].iloc[i] == 4 :
    row = pd.Series([0,0,0,0,1],index=['age_0','age_1','age_2','age_3','age_4'])
    Age = Age.append(row,ignore_index=True)

for i in range(len(df_val)) :
  if df_val['Age'].iloc[0] == 0 :
    row = pd.Series([1,0,0,0,0],index=['age_0','age_1','age_2','age_3','age_4'])
    Age_val = Age_val.append(row,ignore_index=True)
  elif df_val['Age'].iloc[i] == 1 :
    row = pd.Series([0,1,0,0,0],index=['age_0','age_1','age_2','age_3','age_4'])
    Age_val = Age_val.append(row,ignore_index=True)
  elif df_val['Age'].iloc[i] == 2 :
    row = pd.Series([0,0,1,0,0],index=['age_0','age_1','age_2','age_3','age_4'])
    Age_val = Age_val.append(row,ignore_index=True)
  elif df_val['Age'].iloc[i] == 3 :
    row = pd.Series([0,0,0,1,0],index=['age_0','age_1','age_2','age_3','age_4'])
    Age_val = Age_val.append(row,ignore_index=True)
  elif df_val['Age'].iloc[i] == 4 :
    row = pd.Series([0,0,0,0,1],index=['age_0','age_1','age_2','age_3','age_4'])
    Age_val = Age_val.append(row,ignore_index=True)

Y_train_1 = pd.concat([df_train.iloc[:,0:7],Age,df_train.iloc[:,8:9]],axis = 1)
Y_val_1 = pd.concat([df_val.iloc[:,0:7],Age_val,df_val.iloc[:,8:9]],axis = 1)
Y_train_1.head()

Y_train_1 = df_train.iloc[:,0:7]
Y_val_1 = df_val.iloc[:,0:7]

Y_train_onehot_1 = np_utils.to_categorical(Y_train_1)
Y_val_onehot_1 = np_utils.to_categorical(Y_val_1)
print(Y_val_onehot_1)

from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D,Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential
import numpy as np
from glob import glob
import matplotlib.pyplot as plt
from tensorflow.keras.layers import MaxPooling2D

model=Sequential()

model.add(Conv2D(filters=16,kernel_size=(5,5),activation="relu",input_shape=(128,128,1)))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

model.add(Conv2D(filters=32,kernel_size=(5,5),activation ="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(filters=64,kernel_size=(5,5),activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.3))

model.add(Flatten())

#fully connected

model.add(Dense(128,activation="relu"))
model.add(Dropout(0.3))
model.add(Dense(64,activation="relu"))
model.add(Dropout(0.3))

model.add(Dense(2,activation="softmax"))

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

print(model.summary())

history = model.fit(x = X_train_1, y = Y_train_onehot , validation_data = (X_val_1, Y_val_onehot), epochs=20, batch_size=300, verbose=2)

prediction = model.predict(X_test_1)

classes_x = np.argmax(prediction ,axis=1)

X_predict = pd.DataFrame(classes_x, columns = ['Edema'])

X_predict.head(20)
#X_predict.to_csv('107000109_basic_prediction.csv')

from tensorflow.keras import backend
backend.clear_session()

#multi-label
model=Sequential()

model.add(Conv2D(filters=16,kernel_size=(5,5),activation="relu",input_shape=(128,128,1)))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

model.add(Conv2D(filters=32,kernel_size=(5,5),activation ="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(filters=64,kernel_size=(5,5),activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Dropout(0.3))

model.add(Flatten())

model.add(Dense(128,activation="relu"))
model.add(Dropout(0.5))

model.add(Dense(7,activation="sigmoid"))

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

print(model.summary())

history = model.fit(x = X_train_1, y = Y_train_1 , validation_data = (X_val_1, Y_val_1), epochs=10, batch_size=300, verbose=2)

prediction = model.predict(X_test_1)

#classes_x = np.argmax(prediction ,axis=1)

X_predict_ad = pd.DataFrame(prediction, columns = ['Atelectasis','Cardiomegaly','Edema','Lung Opacity','No Finding','Pleural Effusion','Support Devices'])

X_predict_ad_1 = pd.DataFrame(prediction, columns = ['Atelectasis','Cardiomegaly','Edema','Lung Opacity','No Finding','Pleural Effusion','Support Devices'])
#X_predict_ad_1['Atelectasis'][0] = 0
#print(X_predict_ad['Atelectasis'])
for i in X_predict_ad_1 :
  for j in range(len(X_predict_ad_1[i])):
    if X_predict_ad[i][j] > 0.5 :
      print(X_predict_ad[i][j])
      X_predict_ad_1[i][j] = 1
    elif X_predict_ad[i][j] <= 0.5 :
      X_predict_ad_1[i][j] = 0
    
X_predict_ad_1.head(10)

X_predict_ad_1 = X_predict_ad_1.astype(int)
X_predict_ad_1.head(10)

X_predict_ad_1.to_csv('107000109_advanced_prediction.csv')